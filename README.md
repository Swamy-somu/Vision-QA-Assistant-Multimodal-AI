# Vision Q&A Assistant (Multimodal AI)

Multimodal Vision-and-Language AI Assistant using BLIP and Hugging Face Transformers.

---

## 🚀 Features

- Upload images and ask natural language questions about their content (objects, colors, counts, etc.)  
- Supports typed questions and voice questions with automatic speech-to-text transcription  
- Includes OCR to read text (labels, signs, prices) inside images for improved understanding  
- Interactive web demo built with Gradio for easy use  
- Custom evaluation script to measure accuracy on your dataset  

---

## 🔧 Tech Stack

- Python 3.x  
- PyTorch  
- Hugging Face Transformers (BLIP model)  
- EasyOCR for text detection  
- Gradio for web user interface and demo  
- Torchaudio and Whisper ASR for speech transcription  

---

## 🛠️ Installation

1. Clone the repository:
